I"1<h2 id="主要内容">主要内容</h2>
<ul>
  <li><a href="#p1">ABSTRACT</a></li>
  <li><a href="#p2">一、INTRODUCTION</a></li>
  <li><a href="#p3">二、Preliminaries</a></li>
  <li><a href="#p4">三、Methodology</a></li>
  <li><a href="#p5">四、EXPERIMENT</a></li>
</ul>

<h2 id="参考论文">参考论文：</h2>
<p><a href="https://arxiv.org/ftp/arxiv/papers/1911/1911.12093.pdf">《Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting》</a></p>

<p><a href="git@github.com:wumingyao/MAR-BGCN_GPU_pytorch.git">实现链接</a></p>
<h2 id="正文">正文</h2>

<h3 id="abstract"><span id="p1">ABSTRACT</span></h3>
<h4 id="任务objective">任务(Objective)</h4>
<p>任务：交通预测(Traffic frecasting)。</p>
<h4 id="方法methods对研究的基本设计加以描述">方法(Methods)：对研究的基本设计加以描述。</h4>
<p>提出了一个MRA-BGCN(Multi-Range Attentive Bicomponent GCN)用于交通预测。</p>

<p>1) 首先根据路网距离构建节点图，并根据各种边缘交互模式构建边缘图。</p>

<p>2) 我们使用双分量图卷积实现节点和边的交互。</p>

<p>3) 引入了多范围注意力机制来汇总不同邻域范围内的信息，并自动了解不同范围的重要性。</p>
<h4 id="结果results">结果(Results)</h4>
<p>实验结果证明作者提出的方法比现有的方法表现更好。</p>

<h3 id="一introduction"><span id="p2">一、INTRODUCTION</span></h3>
<h4 id="研究背景和重要性background-and-importance">研究背景和重要性(Background And Importance)</h4>
<p>背景：交通预测具有挑战性，对交通管理和公共安全都很重要。</p>

<h4 id="该领域的科研空白挑战description-of-knowledge-gap-or-chanllenge">该领域的科研空白/挑战(Description of knowledge gap or chanllenge)</h4>
<p><img src="../../../../../../img/in-post/2020.08/28/Figure 1.jpg" alt="Figure 1" />
交通预测任务之所以具有挑战性，主要是由于复杂的时空依赖和路网和交通条件带来的潜在的不确定性。
一方面，不规则的道路网导致交通数据之间的复杂依赖关系，另一方面，由于各种不可预测的交通条件，
交通数据是不确定的。</p>

<p>现存工作的空白：</p>

<p>1) 这些方法主要聚焦于通过固定加权图利用GCN建模空间依赖性。然而，边也是很复杂的，并且相互之间有影响。</p>

<p>2) 这些方法通常使用在给定邻域范围内聚集的信息，而忽略多个范围信息。</p>
<h4 id="本文的研究课题topic-of-research-paper">本文的研究课题(Topic Of Research Paper)</h4>
<p>交通预测</p>
<h4 id="核心方法论和主要发现结果highlight-the-approach-and-highlight-principal-findingsresult">核心方法论和主要发现/结果(Highlight The Approach And Highlight Principal Findings/Result)</h4>
<p>核心方法：搭建了一个Multi-Range Attentive Bicomponent GCN(MRA-BGCN),
该模型不仅考虑点的相关性，还考虑边的相关性。</p>

<p>贡献</p>

<p>1) MRA-BGCN同时考虑点和边的相关性。其中，点图是根据路网距离进行搭建，边缘图是通过考虑两种类型的边缘交互模式（流连接性和竞争关系）构建的。竞争关系指的是啥？</p>

<p>2) 在双成分图卷积上应用多范围注意力机制，这样可以捕捉到不同邻居范围和学习到不同范围的重要性。</p>

<p>3) 在METR-LA和PEMS-BAY这两份数据集上做了大量的实验，比现存模型都好。</p>

<h3 id="二preliminaries"><span id="p3">二、Preliminaries</span></h3>

<h4 id="问题定义">问题定义</h4>
<p>给定来自路网中相关交通传感器的历史交通数据，交通预测的任务是预测路网的未来交通。
将𝑁个相关交通传感器定义为加权有向图$G=(V,E,A)$，其中，$V$是$|V|=N$个结点的集合，
$E$是边的集合，$A\in \mathbb{R}^{N\times N}$是带权连接矩阵，代表节点之间的距离。
在$t$时刻在图G上的观测数据标记为一个图信号$X^{(t)}\in \mathbb{R}^{N\times P}$，
其中，$P$是每个节点的特征维度（例如，如果只统计节点的流量，那P==1）。</p>

<p>交通预测任务是在给定$T’$历史图信号和图G的情况下，学习一个函数$f$来预测未来$T$个时间片的图信号</p>

\[[X^{(t-T'+1):t},G] \xrightarrow{f} [X^{(t+1):(t+T)}]\]

<p>其中，$X^{(t-T’+1):t} \in \mathbb{R}^{N\times P\times T’}, X^{(t+1):(t+T)} \in \mathbb{R}^{N\times P\times T}$</p>

<h4 id="graph-convolution">Graph Convolution</h4>
<p>在图$G=(V,E,A)$上定义图卷积</p>

\[\theta_{*G}X=\rho(\tilde{D}^{-1}\tilde{A}X\theta)\tag{1}\]

<p>其中，$X\in\mathbb{R}^{N\times P}$是输入信号，$\theta\in\mathbb{R}^{P\times F}$
是可学习的参数矩阵，$\tilde{A}=A+I_N$是是自连接的邻接矩阵，$\tilde{D}$是$\tilde{A}$
的对角度矩阵。$\tilde{D}^{-1}\tilde{A}$代表规范化邻接矩阵，$\rho$是非线性激活函数。</p>

<p>图卷积可以聚合一跳邻居的信息。 通过堆叠多个图卷积层，我们可以扩展接收邻域范围。</p>
<h3 id="三methodology"><span id="p4">三、Methodology</span></h3>

<h4 id="model-overview">Model Overview</h4>
<p><img src="../../../../../../img/in-post/2020.08/28/Figure 2.jpg" alt="Figure 2" /></p>

<p>如图2所示，MRA-BGCN包含两部分：</p>

<p>1) the bicomponent graph convolution module</p>

<p>该部分包含几个node-wise graph convolution layers和edge-wise graph convolution layers，
可以显式地建模节点和边的交互。</p>

<p>2) the multi-range attention layer</p>

<p>该层层聚合了不同邻域范围内的信息，并学习了不同范围内的重要性。</p>

<h4 id="bicomponent-graph-convolution">Bicomponent Graph Convolution</h4>

<p>图卷积是在给定图结构的情况下对节点交互进行建模的有效操作。
但是，在交通预测中，对边交互进行的建模更加复杂。因此，使用Bicomponent Graph Convolution
对节点和边进行显性建模。</p>

<p>陈等人建议引入边缘邻接线图以建模边缘相关性。</p>

<p>$G=(V,E,A)$代表点图，$G_L=(V_L,E_L,A_L)$是相应的线图，$G_L$图中的点$V_L$
是对应的$E$中的边，例如$V_L=\lbrace (i\rightarrow j);(i,j)\in E$并且$|V_L|=|E|$。
$A_L$是无权邻接矩阵，$A_{L,(i\rightarrow j),(j\rightarrow k)}=1,否则为0$
当一个节点做为一条边的起点，并且做为另一条边的终点时，才认为这两条边时相关的。
<img src="../../../../../../img/in-post/2020.08/28/Figure 3.jpg" alt="Figure 3" /></p>

<p>如图3所示，定义两种类型的边交互模式来构建edge-wise graph $G_e=(V_e,E_e,A_e)$,
每个点$V_e$代表$E$的一条边。</p>

<h4 id="stream-connectivity">Stream connectivity</h4>
<p>在Figure 3(a)中，$(i\rightarrow j)$是$(j\rightarrow k)$的上游边，因此他们是相关联的。
如果结点$j$有大量的邻居，则$(i\rightarrow j)$与$(j\rightarrow k)$之间相关性就比较弱，因为
这条边容易受到其他邻居的影响。
对于stream connectivity的在$A_e$中的边的权重的计算如下：</p>

\[A_{e,(i\rightarrow j),(j\rightarrow k)}=A_{e,(j\rightarrow k),(i\rightarrow j)}=exp(-\frac{(deg^-(j)+deg^+(j)-2)^2}{\sigma ^2})\tag{2}\]

<p>其中，$deg^-(j)$和$deg^+(j)$代表结点$j$的出度和入度，$\sigma$是节点度数的标准偏差。</p>

<h4 id="competitive-relationship">Competitive relationship</h4>
<p>共享同一个源节点的道路链接可能会争夺交通资源并引发竞争关系。
如Figure 3(b),两条边$i\rightarrow k$和$(j\rightarrow k)$共享目标结点$k$是相关联的，
对于Competitive relationship的在$A_e$中的边的权重的计算如下：</p>

\[A_{e,(i\rightarrow k),(j\rightarrow k)}=A_{e,(j\rightarrow k),(i\rightarrow k)}=exp(-\frac{(deg^+(i)+deg^+(j)-2)^2}{\sigma ^2})\tag{3}\]

<p>第k跳的bicomponent graph convolution 公式如下：
<img src="../../../../../../img/in-post/2020.08/28/Tag 4.jpg" alt="Tag 4" /></p>

<p>其中$\theta_{*G}$是带有参数$\theta$的图卷积操作，$[\cdot,\cdot]$是连接操作。
$X^{(l-1)}$是node-wise图卷积$l$层的输入，$Z^{(l-1)}$是edge-wise图卷积$l$
层的输入。$M\in \mathbb{R}^{|V|\times|E|}$是入射矩阵，定义为$M_{i,(i\rightarrow j)}=M_{j,(i\rightarrow j)}=1$否则为0.
$MZ^{(\cdot)}$聚合与每个单个节点连接的边表示,
$M^TX^{(\cdot)}$聚合与每个单边连接的节点表示。
$W_b$是一个可学习的投影矩阵，它将原始节点输入$X^{(0)}$转换为原始边缘输入$Z^{(0)}$。</p>

<h4 id="multi-range-attention">Multi-Range Attention</h4>
<p>我们为双分量图卷积提出了多范围注意机制，以自动了解不同邻域范围的重要性，该功能仅能够汇总不同邻域范围内的信息，而不仅仅是给定邻域范围（即𝑘跳内的邻居）的信息。</p>

<p>双成分图卷积包含不同邻居范围内的点表示，$\chi=\lbrace X^{(1)},X^{(2)},\cdots,X^{(k)},X^{(l)}\in\mathbb{R}^{\vert V \vert\times F}$，
其中，$k$是最大的跳，$F$是每个结点的特征维度，$X_i^{(l)}\in\mathbb{R}^F$表示结点$i$在
$l$层的表示。多范围关注层旨在捕获来自多个邻域范围的集成表示。
为此，首先，将由$W_a\in \mathbb{R}^{F\times F’}$参数化的共享线性变换应用于每层中的每个节点。
通过计算$W_aX_i^{(l)}$和$u$的相似度来测量注意力协方差，其中$u\in\mathbb{R}^{F’}$是
邻居范围内容嵌入。最后，使用SoftMax函数对系数进行归一化。 多范围注意力机制被表述为：
<img src="../../../../../../img/in-post/2020.08/28/Tag 5.jpg" alt="Tag 5" />
一旦获得归一化的注意力系数，我们将为每个节点计算每一层中表示的线性组合，如下所示：</p>

\[h_i=\sum^{k}_{l=1}a_i^{l}X_i^{(l)}\tag{6}\]

<h4 id="bicomponent-graph-convolutional-rnn">Bicomponent Graph Convolutional RNN</h4>
<p>我们将此RNN结构称为双分量图卷积GRU（BGCGRU）。
为了简化公式，我们将$g(X;\theta)$表示为将MRA-BGCN应用于输入$X$，$\theta$是
所有可训练的参数。BGCGRU公式为：
<img src="../../../../../../img/in-post/2020.08/28/Tag 7.jpg" alt="Tag 7" />
其中，$X^{(t)}$和$H^{(t)}$代表在时间步$t$的输入和输出，$z^{(t)}$和$r^{(t)}$
表示在时间步$t$的更新门和重置门，$\sigma$是Sigmoid函数，$\bigodot$是Hadamard 乘积。
<img src="../../../../../../img/in-post/2020.08/28/Figure 4.jpg" alt="Figure 4" />
如图4所示，我们堆叠了多个BGCGRU层，并采用Sequence to Sequence架构进行多步流量预测。</p>
<h3 id="四experiment"><span id="p5">四、EXPERIMENT</span></h3>
<h4 id="experimental-settings">Experimental Settings</h4>
<p>该任务是学习一个函数$f:\mathbb{R}^{N\times P\times T’}\rightarrow\mathbb{R}^{N\times P\times T}$。
在该实验中，$T=T’=12$，BGCGRU的层数是2，带有64个隐藏单元。最大跳数$k$设置为3.
使用Adam优化器进行训练，使用MAE做为监测指标，epochs=100,batch_size=64。
初始学习率为le-2,每10个epochs衰减率为0.6。</p>

<h4 id="effect-of-the-edge-wise-graph">Effect of the Edge-Wise Graph</h4>
<p>为了验证edge-wise graph的有效性，将MRA-BGCN与两个变体进行比较：
1) MRA-BGCN-Identity,该变体忽略边的相关性，并且使用一个单位矩阵来取代边的邻接矩阵。
从本质上讲，这意味着边不会互相影响，而仅由连接的节点确定。
2) MRA-BGCN-LineGraph,该变体使用line graph来取代edge-wise graph，line graph忽略了各种边交互模式。
通过表3可以看处Edge-wise Graph的有效性。直觉是，所提出的Edge-wise Graph考虑了流的连通性和竞争关系，并使模型具有捕获复杂依赖性的能力。
<img src="../../../../../../img/in-post/2020.08/28/Table 3.jpg" alt="Table 3" /></p>

<h4 id="effect-of-the-multi-range-attention-mechanism">Effect of the Multi-Range Attention Mechanism</h4>
<p>为了进一步验证multi-range attention 机制的有效性，作者验证了MRA-BGCN和
使用不同方法来利用多范围信息的两个变体的性能。
1) BGCN,biocomponent graph convolutional network,该网络忽略多范围信息并使用在给定邻域范围内聚合的表示形式（即仅使用第𝑘层的输出）;
2)  MR-BGCN, multi-range bicomponent graph convolutional network,该网络通过在每一层中连接表示来利用多范围信息，并认为来自每个邻域范围的信息都做出了同等贡献。
表4可以看出Multi-Range Attention机制的有效性。</p>

<p><img src="../../../../../../img/in-post/2020.08/28/Table 4.jpg" alt="Table 4" /></p>

<p><img src="../../../../../../img/in-post/2020.08/28/Figure 5.jpg" alt="Figure 5" /></p>
:ET